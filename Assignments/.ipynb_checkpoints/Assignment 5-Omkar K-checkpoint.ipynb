{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1926d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae739f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030e51e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b6afbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5865ee0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dd8806a8e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663e7453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa041ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f9a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b5ae225",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = x_train[55000:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e34647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = y_train[55000:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3155a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1**(1 / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a65279bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "# s = 20 * len(x_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "# learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72949cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6107 - accuracy: 0.8450 - val_loss: 0.2529 - val_accuracy: 0.9334\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2868 - accuracy: 0.9182 - val_loss: 0.1955 - val_accuracy: 0.9468\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2397 - accuracy: 0.9314 - val_loss: 0.1676 - val_accuracy: 0.9564\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2111 - accuracy: 0.9398 - val_loss: 0.1507 - val_accuracy: 0.9602\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1907 - accuracy: 0.9450 - val_loss: 0.1384 - val_accuracy: 0.9632\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1752 - accuracy: 0.9502 - val_loss: 0.1290 - val_accuracy: 0.9668\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1636 - accuracy: 0.9530 - val_loss: 0.1231 - val_accuracy: 0.9674\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1547 - accuracy: 0.9559 - val_loss: 0.1133 - val_accuracy: 0.9700\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1468 - accuracy: 0.9578 - val_loss: 0.1100 - val_accuracy: 0.9714\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1406 - accuracy: 0.9597 - val_loss: 0.1051 - val_accuracy: 0.9726\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1351 - accuracy: 0.9617 - val_loss: 0.1022 - val_accuracy: 0.9718\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1308 - accuracy: 0.9627 - val_loss: 0.0984 - val_accuracy: 0.9752\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1272 - accuracy: 0.9638 - val_loss: 0.0950 - val_accuracy: 0.9740\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1238 - accuracy: 0.9651 - val_loss: 0.0943 - val_accuracy: 0.9754\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1212 - accuracy: 0.9658 - val_loss: 0.0913 - val_accuracy: 0.9760\n",
      "Epoch 16/100\n",
      " 350/1875 [====>.........................] - ETA: 3s - loss: 0.1157 - accuracy: 0.9679"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer= \"sgd\",\n",
    "metrics=[\"accuracy\"])\n",
    "#early stopping\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "restore_best_weights=True)\n",
    "\n",
    "\n",
    "fitted_model = model.fit(x_train,y_train,validation_data=(x_dev,y_dev),epochs=100,callbacks = [tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn),early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57747232",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6046 - accuracy: 0.8425 - val_loss: 0.2525 - val_accuracy: 0.9350\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2891 - accuracy: 0.9184 - val_loss: 0.1995 - val_accuracy: 0.9432\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2414 - accuracy: 0.9314 - val_loss: 0.1721 - val_accuracy: 0.9526\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2121 - accuracy: 0.9401 - val_loss: 0.1523 - val_accuracy: 0.9582\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1914 - accuracy: 0.9453 - val_loss: 0.1366 - val_accuracy: 0.9632\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1758 - accuracy: 0.9498 - val_loss: 0.1273 - val_accuracy: 0.9666\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1636 - accuracy: 0.9535 - val_loss: 0.1194 - val_accuracy: 0.9674\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1538 - accuracy: 0.9559 - val_loss: 0.1118 - val_accuracy: 0.9686\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1460 - accuracy: 0.9580 - val_loss: 0.1073 - val_accuracy: 0.9710\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1396 - accuracy: 0.9603 - val_loss: 0.1037 - val_accuracy: 0.9708\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1344 - accuracy: 0.9622 - val_loss: 0.0997 - val_accuracy: 0.9716\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1300 - accuracy: 0.9632 - val_loss: 0.0963 - val_accuracy: 0.9728\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1261 - accuracy: 0.9645 - val_loss: 0.0940 - val_accuracy: 0.9734\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1229 - accuracy: 0.9652 - val_loss: 0.0920 - val_accuracy: 0.9744\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1201 - accuracy: 0.9659 - val_loss: 0.0899 - val_accuracy: 0.9746\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1178 - accuracy: 0.9667 - val_loss: 0.0884 - val_accuracy: 0.9750\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1158 - accuracy: 0.9675 - val_loss: 0.0870 - val_accuracy: 0.9754\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1139 - accuracy: 0.9677 - val_loss: 0.0859 - val_accuracy: 0.9766\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1124 - accuracy: 0.9680 - val_loss: 0.0849 - val_accuracy: 0.9772\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1111 - accuracy: 0.9688 - val_loss: 0.0837 - val_accuracy: 0.9768\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1098 - accuracy: 0.9692 - val_loss: 0.0841 - val_accuracy: 0.9774\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1087 - accuracy: 0.9693 - val_loss: 0.0821 - val_accuracy: 0.9780\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1079 - accuracy: 0.9696 - val_loss: 0.0815 - val_accuracy: 0.9774\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1071 - accuracy: 0.9699 - val_loss: 0.0810 - val_accuracy: 0.9786\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1063 - accuracy: 0.9701 - val_loss: 0.0810 - val_accuracy: 0.9790\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1057 - accuracy: 0.9703 - val_loss: 0.0803 - val_accuracy: 0.9790\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1052 - accuracy: 0.9706 - val_loss: 0.0798 - val_accuracy: 0.9784\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1047 - accuracy: 0.9707 - val_loss: 0.0798 - val_accuracy: 0.9790\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1042 - accuracy: 0.9708 - val_loss: 0.0793 - val_accuracy: 0.9790\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1038 - accuracy: 0.9708 - val_loss: 0.0790 - val_accuracy: 0.9794\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1035 - accuracy: 0.9710 - val_loss: 0.0789 - val_accuracy: 0.9792\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1032 - accuracy: 0.9712 - val_loss: 0.0787 - val_accuracy: 0.9792\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1029 - accuracy: 0.9713 - val_loss: 0.0784 - val_accuracy: 0.9794\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1027 - accuracy: 0.9712 - val_loss: 0.0783 - val_accuracy: 0.9794\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1025 - accuracy: 0.9714 - val_loss: 0.0783 - val_accuracy: 0.9796\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1023 - accuracy: 0.9714 - val_loss: 0.0781 - val_accuracy: 0.9794\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1021 - accuracy: 0.9714 - val_loss: 0.0780 - val_accuracy: 0.9794\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1019 - accuracy: 0.9714 - val_loss: 0.0779 - val_accuracy: 0.9794\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1018 - accuracy: 0.9713 - val_loss: 0.0778 - val_accuracy: 0.9794\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1017 - accuracy: 0.9715 - val_loss: 0.0777 - val_accuracy: 0.9794\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1016 - accuracy: 0.9715 - val_loss: 0.0777 - val_accuracy: 0.9796\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1015 - accuracy: 0.9714 - val_loss: 0.0776 - val_accuracy: 0.9796\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1014 - accuracy: 0.9714 - val_loss: 0.0775 - val_accuracy: 0.9796\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1013 - accuracy: 0.9715 - val_loss: 0.0775 - val_accuracy: 0.9796\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1013 - accuracy: 0.9715 - val_loss: 0.0774 - val_accuracy: 0.9796\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1012 - accuracy: 0.9716 - val_loss: 0.0774 - val_accuracy: 0.9796\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1012 - accuracy: 0.9716 - val_loss: 0.0774 - val_accuracy: 0.9796\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1011 - accuracy: 0.9716 - val_loss: 0.0773 - val_accuracy: 0.9796\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1011 - accuracy: 0.9715 - val_loss: 0.0773 - val_accuracy: 0.9796\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1010 - accuracy: 0.9716 - val_loss: 0.0773 - val_accuracy: 0.9796\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1010 - accuracy: 0.9715 - val_loss: 0.0773 - val_accuracy: 0.9796\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1010 - accuracy: 0.9716 - val_loss: 0.0773 - val_accuracy: 0.9796\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1009 - accuracy: 0.9716 - val_loss: 0.0772 - val_accuracy: 0.9796\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1009 - accuracy: 0.9716 - val_loss: 0.0772 - val_accuracy: 0.9796\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1009 - accuracy: 0.9716 - val_loss: 0.0772 - val_accuracy: 0.9796\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1009 - accuracy: 0.9715 - val_loss: 0.0772 - val_accuracy: 0.9796\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1009 - accuracy: 0.9717 - val_loss: 0.0772 - val_accuracy: 0.9796\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1008 - accuracy: 0.9716 - val_loss: 0.0772 - val_accuracy: 0.9796\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1008 - accuracy: 0.9716 - val_loss: 0.0772 - val_accuracy: 0.9796\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1008 - accuracy: 0.9716 - val_loss: 0.0772 - val_accuracy: 0.9796\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1008 - accuracy: 0.9716 - val_loss: 0.0772 - val_accuracy: 0.9796\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1008 - accuracy: 0.9716 - val_loss: 0.0772 - val_accuracy: 0.9796\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1008 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1008 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1008 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1008 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1008 - accuracy: 0.9717 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1008 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9716 - val_loss: 0.0771 - val_accuracy: 0.9796\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer= \"sgd\",\n",
    "metrics=[\"accuracy\"])\n",
    "#early stopping\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "restore_best_weights=True)\n",
    "\n",
    "#checkpoint\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
    "save_best_only=True)\n",
    "\n",
    "fitted_model = model.fit(x_train,y_train,validation_data=(x_dev,y_dev),epochs=100,callbacks = [tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn),early_stopping_cb,checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3beb1502",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.05645854026079178,\n",
       "  0.052287355065345764,\n",
       "  0.04965481534600258,\n",
       "  0.0469915047287941,\n",
       "  0.0447084903717041,\n",
       "  0.042936231940984726,\n",
       "  0.0413186214864254,\n",
       "  0.04007710516452789,\n",
       "  0.0388333797454834,\n",
       "  0.0378531813621521,\n",
       "  0.036905065178871155,\n",
       "  0.036219969391822815,\n",
       "  0.03544873744249344,\n",
       "  0.034937452524900436,\n",
       "  0.034345027059316635,\n",
       "  0.03395256772637367,\n",
       "  0.033552415668964386,\n",
       "  0.033205900341272354,\n",
       "  0.03290174528956413,\n",
       "  0.03261624649167061,\n",
       "  0.03236225247383118,\n",
       "  0.03217567503452301,\n",
       "  0.03198078274726868,\n",
       "  0.03178975731134415,\n",
       "  0.031660813838243484,\n",
       "  0.031517211347818375,\n",
       "  0.03141797333955765,\n",
       "  0.03132190182805061,\n",
       "  0.03121192194521427,\n",
       "  0.0311374943703413,\n",
       "  0.031052306294441223,\n",
       "  0.03097674623131752,\n",
       "  0.03093385137617588,\n",
       "  0.03087795339524746,\n",
       "  0.030835537239909172,\n",
       "  0.03078712336719036,\n",
       "  0.030752861872315407,\n",
       "  0.030722089111804962,\n",
       "  0.03069090098142624,\n",
       "  0.03066611848771572,\n",
       "  0.03064088523387909,\n",
       "  0.030620917677879333,\n",
       "  0.030601905658841133,\n",
       "  0.030585406348109245,\n",
       "  0.030570054426789284,\n",
       "  0.03055722266435623,\n",
       "  0.03054473176598549,\n",
       "  0.030534662306308746,\n",
       "  0.030525287613272667,\n",
       "  0.030517268925905228,\n",
       "  0.03050943650305271,\n",
       "  0.030502887442708015,\n",
       "  0.0304969921708107,\n",
       "  0.030491730198264122,\n",
       "  0.030487168580293655,\n",
       "  0.030482983216643333,\n",
       "  0.03047926351428032,\n",
       "  0.030475929379463196,\n",
       "  0.030473055317997932,\n",
       "  0.030470261350274086,\n",
       "  0.03046799637377262,\n",
       "  0.03046591393649578,\n",
       "  0.03046410158276558,\n",
       "  0.030462462455034256,\n",
       "  0.03046111948788166,\n",
       "  0.0304598119109869,\n",
       "  0.03045865148305893,\n",
       "  0.03045770525932312,\n",
       "  0.03045676089823246,\n",
       "  0.030456027016043663,\n",
       "  0.030455270782113075,\n",
       "  0.030454667285084724,\n",
       "  0.030454155057668686,\n",
       "  0.030453719198703766,\n",
       "  0.03045319765806198,\n",
       "  0.030452851206064224,\n",
       "  0.030452538281679153,\n",
       "  0.03045223467051983,\n",
       "  0.03045196644961834,\n",
       "  0.03045172244310379,\n",
       "  0.03045162744820118,\n",
       "  0.03045141138136387,\n",
       "  0.030451282858848572,\n",
       "  0.030451186001300812,\n",
       "  0.030450988560914993,\n",
       "  0.030450932681560516,\n",
       "  0.030450869351625443,\n",
       "  0.030450791120529175],\n",
       " 'accuracy': [0.9843500256538391,\n",
       "  0.9861833453178406,\n",
       "  0.9868500232696533,\n",
       "  0.98785001039505,\n",
       "  0.9886166453361511,\n",
       "  0.9887999892234802,\n",
       "  0.9894166588783264,\n",
       "  0.9899666905403137,\n",
       "  0.9906333088874817,\n",
       "  0.9908999800682068,\n",
       "  0.991433322429657,\n",
       "  0.9915333390235901,\n",
       "  0.9919166564941406,\n",
       "  0.9919666647911072,\n",
       "  0.9922333359718323,\n",
       "  0.9923666715621948,\n",
       "  0.9924833178520203,\n",
       "  0.9925333261489868,\n",
       "  0.9928333163261414,\n",
       "  0.9925500154495239,\n",
       "  0.9926166534423828,\n",
       "  0.9929333329200745,\n",
       "  0.9929333329200745,\n",
       "  0.9930166602134705,\n",
       "  0.9930333495140076,\n",
       "  0.993066668510437,\n",
       "  0.9931333065032959,\n",
       "  0.9930833578109741,\n",
       "  0.9932000041007996,\n",
       "  0.9931666851043701,\n",
       "  0.9932166934013367,\n",
       "  0.9932833313941956,\n",
       "  0.9932500123977661,\n",
       "  0.9932500123977661,\n",
       "  0.9933000206947327,\n",
       "  0.9933333396911621,\n",
       "  0.9933500289916992,\n",
       "  0.9933000206947327,\n",
       "  0.993399977684021,\n",
       "  0.9933000206947327,\n",
       "  0.9933833479881287,\n",
       "  0.9933833479881287,\n",
       "  0.9933833479881287,\n",
       "  0.9933666586875916,\n",
       "  0.9933666586875916,\n",
       "  0.9934166669845581,\n",
       "  0.993399977684021,\n",
       "  0.9934499859809875,\n",
       "  0.9934166669845581,\n",
       "  0.9934166669845581,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934333562850952,\n",
       "  0.9934499859809875,\n",
       "  0.9934333562850952,\n",
       "  0.9934499859809875,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934499859809875,\n",
       "  0.9934666752815247,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934499859809875,\n",
       "  0.9934666752815247,\n",
       "  0.9934499859809875,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247],\n",
       " 'val_loss': [0.04149575158953667,\n",
       "  0.04140181094408035,\n",
       "  0.037085454910993576,\n",
       "  0.03739344701170921,\n",
       "  0.03492371737957001,\n",
       "  0.03337500989437103,\n",
       "  0.03192342072725296,\n",
       "  0.031937193125486374,\n",
       "  0.03143905848264694,\n",
       "  0.030720654875040054,\n",
       "  0.029859809204936028,\n",
       "  0.029685931280255318,\n",
       "  0.02876046486198902,\n",
       "  0.028073778375983238,\n",
       "  0.028062164783477783,\n",
       "  0.02778269350528717,\n",
       "  0.027704430744051933,\n",
       "  0.027623426169157028,\n",
       "  0.02744561992585659,\n",
       "  0.02719351463019848,\n",
       "  0.026881828904151917,\n",
       "  0.026930764317512512,\n",
       "  0.026565691456198692,\n",
       "  0.02679019421339035,\n",
       "  0.026436688378453255,\n",
       "  0.026678822934627533,\n",
       "  0.026341106742620468,\n",
       "  0.026342589408159256,\n",
       "  0.02629425749182701,\n",
       "  0.02627706341445446,\n",
       "  0.026339413598179817,\n",
       "  0.026164108887314796,\n",
       "  0.026165654882788658,\n",
       "  0.026137609034776688,\n",
       "  0.026160098612308502,\n",
       "  0.026111343875527382,\n",
       "  0.026080569252371788,\n",
       "  0.026050729677081108,\n",
       "  0.026017842814326286,\n",
       "  0.02602514997124672,\n",
       "  0.026026641950011253,\n",
       "  0.026008188724517822,\n",
       "  0.0259998831897974,\n",
       "  0.025983670726418495,\n",
       "  0.025971654802560806,\n",
       "  0.025957003235816956,\n",
       "  0.025954613462090492,\n",
       "  0.025947077199816704,\n",
       "  0.02593926154077053,\n",
       "  0.02593310922384262,\n",
       "  0.025931647047400475,\n",
       "  0.02592928148806095,\n",
       "  0.025925319641828537,\n",
       "  0.025922372937202454,\n",
       "  0.025919783860445023,\n",
       "  0.025917647406458855,\n",
       "  0.02591559663414955,\n",
       "  0.025913672521710396,\n",
       "  0.02591189183294773,\n",
       "  0.0259105172008276,\n",
       "  0.02590930089354515,\n",
       "  0.025908557698130608,\n",
       "  0.025907596573233604,\n",
       "  0.025906922295689583,\n",
       "  0.025906221941113472,\n",
       "  0.025905689224600792,\n",
       "  0.02590523287653923,\n",
       "  0.02590477280318737,\n",
       "  0.025904443114995956,\n",
       "  0.02590414136648178,\n",
       "  0.025903958827257156,\n",
       "  0.02590375579893589,\n",
       "  0.0259036123752594,\n",
       "  0.02590353414416313,\n",
       "  0.02590351551771164,\n",
       "  0.025903476402163506,\n",
       "  0.025903478264808655,\n",
       "  0.025903457775712013,\n",
       "  0.025903500616550446,\n",
       "  0.02590356394648552,\n",
       "  0.025903649628162384,\n",
       "  0.025903716683387756,\n",
       "  0.025903772562742233,\n",
       "  0.02590382657945156,\n",
       "  0.025903863832354546,\n",
       "  0.025903893634676933,\n",
       "  0.025903958827257156,\n",
       "  0.025904059410095215],\n",
       " 'val_accuracy': [0.989799976348877,\n",
       "  0.9909999966621399,\n",
       "  0.9919999837875366,\n",
       "  0.9919999837875366,\n",
       "  0.9927999973297119,\n",
       "  0.9944000244140625,\n",
       "  0.9936000108718872,\n",
       "  0.9937999844551086,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9945999979972839,\n",
       "  0.9945999979972839,\n",
       "  0.9950000047683716,\n",
       "  0.9954000115394592,\n",
       "  0.9945999979972839,\n",
       "  0.9947999715805054,\n",
       "  0.995199978351593,\n",
       "  0.9955999851226807,\n",
       "  0.995199978351593,\n",
       "  0.995199978351593,\n",
       "  0.9955999851226807,\n",
       "  0.9954000115394592,\n",
       "  0.9958000183105469,\n",
       "  0.9958000183105469,\n",
       "  0.9954000115394592,\n",
       "  0.9955999851226807,\n",
       "  0.9954000115394592,\n",
       "  0.9955999851226807,\n",
       "  0.9954000115394592,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.995199978351593,\n",
       "  0.9954000115394592,\n",
       "  0.9954000115394592,\n",
       "  0.9954000115394592,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9954000115394592,\n",
       "  0.9954000115394592,\n",
       "  0.9954000115394592,\n",
       "  0.9954000115394592,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807,\n",
       "  0.9955999851226807],\n",
       " 'lr': [0.008912509,\n",
       "  0.007943282,\n",
       "  0.0070794574,\n",
       "  0.006309573,\n",
       "  0.005623413,\n",
       "  0.005011872,\n",
       "  0.0044668354,\n",
       "  0.003981071,\n",
       "  0.0035481334,\n",
       "  0.0031622772,\n",
       "  0.0028183826,\n",
       "  0.0025118862,\n",
       "  0.002238721,\n",
       "  0.001995262,\n",
       "  0.0017782791,\n",
       "  0.0015848929,\n",
       "  0.0014125373,\n",
       "  0.0012589252,\n",
       "  0.0011220182,\n",
       "  0.0009999998,\n",
       "  0.0008912508,\n",
       "  0.0007943281,\n",
       "  0.00070794567,\n",
       "  0.00063095725,\n",
       "  0.00056234124,\n",
       "  0.00050118717,\n",
       "  0.00044668352,\n",
       "  0.0003981071,\n",
       "  0.00035481332,\n",
       "  0.0003162277,\n",
       "  0.00028183823,\n",
       "  0.00025118858,\n",
       "  0.00022387206,\n",
       "  0.00019952618,\n",
       "  0.0001778279,\n",
       "  0.00015848927,\n",
       "  0.00014125371,\n",
       "  0.0001258925,\n",
       "  0.000112201815,\n",
       "  9.9999976e-05,\n",
       "  8.9125075e-05,\n",
       "  7.943281e-05,\n",
       "  7.0794566e-05,\n",
       "  6.309572e-05,\n",
       "  5.6234123e-05,\n",
       "  5.0118713e-05,\n",
       "  4.466835e-05,\n",
       "  3.981071e-05,\n",
       "  3.5481335e-05,\n",
       "  3.1622774e-05,\n",
       "  2.8183827e-05,\n",
       "  2.5118863e-05,\n",
       "  2.238721e-05,\n",
       "  1.9952622e-05,\n",
       "  1.7782793e-05,\n",
       "  1.5848931e-05,\n",
       "  1.4125375e-05,\n",
       "  1.2589254e-05,\n",
       "  1.1220184e-05,\n",
       "  1e-05,\n",
       "  8.912509e-06,\n",
       "  7.943282e-06,\n",
       "  7.0794576e-06,\n",
       "  6.309573e-06,\n",
       "  5.623413e-06,\n",
       "  5.011872e-06,\n",
       "  4.4668354e-06,\n",
       "  3.981071e-06,\n",
       "  3.5481335e-06,\n",
       "  3.1622774e-06,\n",
       "  2.8183827e-06,\n",
       "  2.5118861e-06,\n",
       "  2.2387208e-06,\n",
       "  1.995262e-06,\n",
       "  1.7782792e-06,\n",
       "  1.584893e-06,\n",
       "  1.4125374e-06,\n",
       "  1.2589253e-06,\n",
       "  1.1220184e-06,\n",
       "  9.999999e-07,\n",
       "  8.912508e-07,\n",
       "  7.943281e-07,\n",
       "  7.079457e-07,\n",
       "  6.3095723e-07,\n",
       "  5.623412e-07,\n",
       "  5.011871e-07,\n",
       "  4.466835e-07,\n",
       "  3.981071e-07]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d36bbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a83c9ae760>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fitted_model.history['lr'], fitted_model.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37771beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
