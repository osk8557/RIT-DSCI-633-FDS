{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9898e3c6",
   "metadata": {},
   "source": [
    "# Step 0 - import NN libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1926d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3d658",
   "metadata": {},
   "source": [
    "# Step 1 - Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae739f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030e51e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b6afbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5865ee0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11ee89dba00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOX0lEQVR4nO3dbYxc5XnG8euKbUwxJvHGseMQFxzjFAg0Jl0ZkBFQoVCCIgGKCLGiiFBapwlOQutKUFoVWtHKrRIiSimSKS6m4iWQgPAHmsSyECRqcFmoAROHN+MS4+0aswIDIfZ6fffDjqsFdp5dZs68eO//T1rNzLnnzLk1cPmcmeeceRwRAjD5faDTDQBoD8IOJEHYgSQIO5AEYQeSmNrOjR3i6XGoZrRzk0Aqv9Fb2ht7PFatqbDbPkfS9ZKmSPrXiFhVev6hmqGTfVYzmwRQsDE21K01fBhve4qkGyV9TtLxkpbZPr7R1wPQWs18Zl8i6fmI2BoReyXdJem8atoCULVmwn6kpF+Nery9tuwdbC+33We7b0h7mtgcgGY0E/axvgR4z7m3EbE6InojoneapjexOQDNaCbs2yXNH/X445J2NNcOgFZpJuyPSlpke4HtQyR9SdK6atoCULWGh94iYp/tFZJ+rJGhtzUR8XRlnQGoVFPj7BHxgKQHKuoFQAtxuiyQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJNDWLK7qfp5b/E0/5yOyWbv+ZPz+6bm34sP3FdY9auLNYP+wbLtb/97pD6tYe7/1+cd1dw28V6yffs7JYP+bPHinWO6GpsNveJukNScOS9kVEbxVNAaheFXv234+IXRW8DoAW4jM7kESzYQ9JP7H9mO3lYz3B9nLbfbb7hrSnyc0BaFSzh/FLI2KH7TmS1tv+ZUQ8PPoJEbFa0mpJOsI90eT2ADSoqT17ROyo3e6UdJ+kJVU0BaB6DYfd9gzbMw/cl3S2pM1VNQagWs0cxs+VdJ/tA69zR0T8qJKuJpkpxy0q1mP6tGJ9xxkfKtbfPqX+mHDPB8vjxT/9dHm8uZP+49czi/V/+OdzivWNJ95Rt/bi0NvFdVcNfLZY/9hPD75PpA2HPSK2Svp0hb0AaCGG3oAkCDuQBGEHkiDsQBKEHUiCS1wrMHzmZ4r16269sVj/5LT6l2JOZkMxXKz/9Q1fLdanvlUe/jr1nhV1azNf3ldcd/qu8tDcYX0bi/VuxJ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnL0C05/ZUaw/9pv5xfonpw1U2U6lVvafUqxvfbP8U9S3LvxB3drr+8vj5HP/6T+L9VY6+C5gHR97diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwhHtG1E8wj1xss9q2/a6xeAlpxbru88p/9zzlCcPL9af+MYN77unA67d9bvF+qNnlMfRh197vViPU+v/APG2bxVX1YJlT5SfgPfYGBu0OwbHnMuaPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4exeYMvvDxfrwq4PF+ot31B8rf/r0NcV1l/z9N4v1OTd27ppyvH9NjbPbXmN7p+3No5b12F5v+7na7awqGwZQvYkcxt8q6d2z3l8paUNELJK0ofYYQBcbN+wR8bCkdx9Hnidpbe3+WknnV9sWgKo1+gXd3Ijol6Ta7Zx6T7S93Haf7b4h7WlwcwCa1fJv4yNidUT0RkTvNE1v9eYA1NFo2Adsz5Ok2u3O6loC0AqNhn2dpItr9y+WdH817QBolXF/N972nZLOlDTb9nZJV0taJelu25dKeknSha1scrIb3vVqU+sP7W58fvdPffkXxforN00pv8D+8hzr6B7jhj0iltUpcXYMcBDhdFkgCcIOJEHYgSQIO5AEYQeSYMrmSeC4K56tW7vkxPKgyb8dtaFYP+PCy4r1md9/pFhH92DPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+CZSmTX7168cV131p3dvF+pXX3las/8UXLyjW478/WLc2/+9+XlxXbfyZ8wzYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEkzZnNzgH55arN9+9XeK9QVTD21425+6bUWxvujm/mJ939ZtDW97smpqymYAkwNhB5Ig7EAShB1IgrADSRB2IAnCDiTBODuKYuniYv2IVduL9Ts/8eOGt33sg39UrP/O39S/jl+Shp/b2vC2D1ZNjbPbXmN7p+3No5ZdY/tl25tqf+dW2TCA6k3kMP5WSeeMsfx7EbG49vdAtW0BqNq4YY+IhyUNtqEXAC3UzBd0K2w/WTvMn1XvSbaX2+6z3TekPU1sDkAzGg37TZIWSlosqV/Sd+s9MSJWR0RvRPRO0/QGNwegWQ2FPSIGImI4IvZLulnSkmrbAlC1hsJue96ohxdI2lzvuQC6w7jj7LbvlHSmpNmSBiRdXXu8WFJI2ibpaxFRvvhYjLNPRlPmzinWd1x0TN3axiuuL677gXH2RV9+8exi/fXTXi3WJ6PSOPu4k0RExLIxFt/SdFcA2orTZYEkCDuQBGEHkiDsQBKEHUiCS1zRMXdvL0/ZfJgPKdZ/HXuL9c9/8/L6r33fxuK6Byt+ShoAYQeyIOxAEoQdSIKwA0kQdiAJwg4kMe5Vb8ht/2mLi/UXLixP2XzC4m11a+ONo4/nhsGTivXD7u9r6vUnG/bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+yTnHtPKNaf/VZ5rPvmpWuL9dMPLV9T3ow9MVSsPzK4oPwC+8f9dfNU2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMsx8Epi44qlh/4ZKP1a1dc9FdxXW/cPiuhnqqwlUDvcX6Q9efUqzPWlv+3Xm807h7dtvzbT9oe4vtp21/u7a8x/Z628/Vbme1vl0AjZrIYfw+SSsj4jhJp0i6zPbxkq6UtCEiFknaUHsMoEuNG/aI6I+Ix2v335C0RdKRks6TdOBcyrWSzm9RjwAq8L6+oLN9tKSTJG2UNDci+qWRfxAkzamzznLbfbb7hrSnyXYBNGrCYbd9uKQfSro8InZPdL2IWB0RvRHRO03TG+kRQAUmFHbb0zQS9Nsj4t7a4gHb82r1eZJ2tqZFAFUYd+jNtiXdImlLRFw3qrRO0sWSVtVu729Jh5PA1KN/u1h//ffmFesX/e2PivU/+dC9xXorrewvD4/9/F/qD6/13PpfxXVn7WdorUoTGWdfKukrkp6yvam27CqNhPxu25dKeknShS3pEEAlxg17RPxM0piTu0s6q9p2ALQKp8sCSRB2IAnCDiRB2IEkCDuQBJe4TtDUeR+tWxtcM6O47tcXPFSsL5s50FBPVVjx8mnF+uM3LS7WZ/9gc7He8wZj5d2CPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJJFmnH3vH5R/tnjvnw4W61cd80Dd2tm/9VZDPVVlYPjturXT160srnvsX/2yWO95rTxOvr9YRTdhzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSaQZZ992fvnftWdPvKdl277xtYXF+vUPnV2se7jej/uOOPbaF+vWFg1sLK47XKxiMmHPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJOCLKT7DnS7pN0kc1cvny6oi43vY1kv5Y0iu1p14VEfUv+pZ0hHviZDPxK9AqG2ODdsfgmCdmTOSkmn2SVkbE47ZnSnrM9vpa7XsR8Z2qGgXQOhOZn71fUn/t/hu2t0g6stWNAajW+/rMbvtoSSdJOnAO5grbT9peY3tWnXWW2+6z3TekPc11C6BhEw677cMl/VDS5RGxW9JNkhZKWqyRPf93x1ovIlZHRG9E9E7T9OY7BtCQCYXd9jSNBP32iLhXkiJiICKGI2K/pJslLWldmwCaNW7YbVvSLZK2RMR1o5bPG/W0CySVp/ME0FET+TZ+qaSvSHrK9qbasqskLbO9WFJI2ibpay3oD0BFJvJt/M8kjTVuVxxTB9BdOIMOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQxLg/JV3pxuxXJP3PqEWzJe1qWwPvT7f21q19SfTWqCp7OyoiPjJWoa1hf8/G7b6I6O1YAwXd2lu39iXRW6Pa1RuH8UAShB1IotNhX93h7Zd0a2/d2pdEb41qS28d/cwOoH06vWcH0CaEHUiiI2G3fY7tZ2w/b/vKTvRQj+1ttp+yvcl2X4d7WWN7p+3No5b12F5v+7na7Zhz7HWot2tsv1x77zbZPrdDvc23/aDtLbaftv3t2vKOvneFvtryvrX9M7vtKZKelfRZSdslPSppWUT8oq2N1GF7m6TeiOj4CRi2T5f0pqTbIuKE2rJ/lDQYEatq/1DOiogruqS3ayS92elpvGuzFc0bPc24pPMlfVUdfO8KfX1RbXjfOrFnXyLp+YjYGhF7Jd0l6bwO9NH1IuJhSYPvWnyepLW1+2s18j9L29XprStERH9EPF67/4akA9OMd/S9K/TVFp0I+5GSfjXq8XZ113zvIeknth+zvbzTzYxhbkT0SyP/80ia0+F+3m3cabzb6V3TjHfNe9fI9OfN6kTYx5pKqpvG/5ZGxGckfU7SZbXDVUzMhKbxbpcxphnvCo1Of96sToR9u6T5ox5/XNKODvQxpojYUbvdKek+dd9U1AMHZtCt3e7scD//r5um8R5rmnF1wXvXyenPOxH2RyUtsr3A9iGSviRpXQf6eA/bM2pfnMj2DElnq/umol4n6eLa/Ysl3d/BXt6hW6bxrjfNuDr83nV8+vOIaPufpHM18o38C5L+shM91OnrE5KeqP093eneJN2pkcO6IY0cEV0q6cOSNkh6rnbb00W9/bukpyQ9qZFgzetQb6dp5KPhk5I21f7O7fR7V+irLe8bp8sCSXAGHZAEYQeSIOxAEoQdSIKwA0kQdiAJwg4k8X+zhHFo7nUhhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663e7453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cd7faa",
   "metadata": {},
   "source": [
    "# Step 2 - Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa041ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f9a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ae650e",
   "metadata": {},
   "source": [
    "# Step 3 - Divide dataset into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b5ae225",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = x_train[55000:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e34647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = y_train[55000:60000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd12f170",
   "metadata": {},
   "source": [
    "# Step 4 - Build a simple dense network, use ExponentialLearningRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3155a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1**(1 / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e4389",
   "metadata": {},
   "source": [
    "# Step 5 - Use sigmoid, relu, and softmax as activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a65279bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bace7",
   "metadata": {},
   "source": [
    "# Step 6 - Plot loss as a function of learning rate\n",
    "# Step 8 - compile losses, use various optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4efc85eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6201 - accuracy: 0.8369 - val_loss: 0.2575 - val_accuracy: 0.9320\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2915 - accuracy: 0.9162 - val_loss: 0.2003 - val_accuracy: 0.9464\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2425 - accuracy: 0.9317 - val_loss: 0.1733 - val_accuracy: 0.9534\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2128 - accuracy: 0.9390 - val_loss: 0.1540 - val_accuracy: 0.9586\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1929 - accuracy: 0.9452 - val_loss: 0.1415 - val_accuracy: 0.9638\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1775 - accuracy: 0.9495 - val_loss: 0.1304 - val_accuracy: 0.9654\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1659 - accuracy: 0.9519 - val_loss: 0.1234 - val_accuracy: 0.9676\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1566 - accuracy: 0.9553 - val_loss: 0.1161 - val_accuracy: 0.9682\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1487 - accuracy: 0.9576 - val_loss: 0.1107 - val_accuracy: 0.9704\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1428 - accuracy: 0.9590 - val_loss: 0.1075 - val_accuracy: 0.9716\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1373 - accuracy: 0.9612 - val_loss: 0.1044 - val_accuracy: 0.9728\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1330 - accuracy: 0.9624 - val_loss: 0.1014 - val_accuracy: 0.9736\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1292 - accuracy: 0.9635 - val_loss: 0.0985 - val_accuracy: 0.9738\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1260 - accuracy: 0.9644 - val_loss: 0.0961 - val_accuracy: 0.9748\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1233 - accuracy: 0.9656 - val_loss: 0.0948 - val_accuracy: 0.9752\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1208 - accuracy: 0.9664 - val_loss: 0.0935 - val_accuracy: 0.9756\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1189 - accuracy: 0.9666 - val_loss: 0.0922 - val_accuracy: 0.9754\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1170 - accuracy: 0.9673 - val_loss: 0.0908 - val_accuracy: 0.9762\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1156 - accuracy: 0.9677 - val_loss: 0.0900 - val_accuracy: 0.9772\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1141 - accuracy: 0.9682 - val_loss: 0.0889 - val_accuracy: 0.9768\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1129 - accuracy: 0.9684 - val_loss: 0.0889 - val_accuracy: 0.9768\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1119 - accuracy: 0.9689 - val_loss: 0.0874 - val_accuracy: 0.9772\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1110 - accuracy: 0.9691 - val_loss: 0.0866 - val_accuracy: 0.9772\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1102 - accuracy: 0.9691 - val_loss: 0.0864 - val_accuracy: 0.9776\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1094 - accuracy: 0.9695 - val_loss: 0.0856 - val_accuracy: 0.9766\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1088 - accuracy: 0.9696 - val_loss: 0.0852 - val_accuracy: 0.9772\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1082 - accuracy: 0.9701 - val_loss: 0.0852 - val_accuracy: 0.9772\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1077 - accuracy: 0.9702 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1073 - accuracy: 0.9702 - val_loss: 0.0845 - val_accuracy: 0.9774\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1069 - accuracy: 0.9703 - val_loss: 0.0841 - val_accuracy: 0.9782\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1065 - accuracy: 0.9706 - val_loss: 0.0839 - val_accuracy: 0.9778\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1062 - accuracy: 0.9704 - val_loss: 0.0837 - val_accuracy: 0.9780\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1059 - accuracy: 0.9708 - val_loss: 0.0837 - val_accuracy: 0.9778\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1057 - accuracy: 0.9709 - val_loss: 0.0833 - val_accuracy: 0.9780\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1055 - accuracy: 0.9709 - val_loss: 0.0833 - val_accuracy: 0.9776\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1053 - accuracy: 0.9709 - val_loss: 0.0831 - val_accuracy: 0.9780\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1051 - accuracy: 0.9710 - val_loss: 0.0830 - val_accuracy: 0.9780\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1049 - accuracy: 0.9710 - val_loss: 0.0829 - val_accuracy: 0.9780\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1048 - accuracy: 0.9711 - val_loss: 0.0829 - val_accuracy: 0.9780\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1047 - accuracy: 0.9711 - val_loss: 0.0827 - val_accuracy: 0.9780\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1046 - accuracy: 0.9710 - val_loss: 0.0826 - val_accuracy: 0.9780\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1045 - accuracy: 0.9711 - val_loss: 0.0826 - val_accuracy: 0.9780\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1044 - accuracy: 0.9711 - val_loss: 0.0825 - val_accuracy: 0.9782\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1043 - accuracy: 0.9712 - val_loss: 0.0825 - val_accuracy: 0.9782\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1042 - accuracy: 0.9712 - val_loss: 0.0824 - val_accuracy: 0.9782\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1042 - accuracy: 0.9712 - val_loss: 0.0824 - val_accuracy: 0.9780\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1041 - accuracy: 0.9712 - val_loss: 0.0823 - val_accuracy: 0.9782\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1041 - accuracy: 0.9712 - val_loss: 0.0823 - val_accuracy: 0.9782\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1040 - accuracy: 0.9712 - val_loss: 0.0823 - val_accuracy: 0.9782\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1040 - accuracy: 0.9712 - val_loss: 0.0823 - val_accuracy: 0.9782\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1040 - accuracy: 0.9712 - val_loss: 0.0823 - val_accuracy: 0.9782\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1039 - accuracy: 0.9712 - val_loss: 0.0822 - val_accuracy: 0.9782\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1039 - accuracy: 0.9713 - val_loss: 0.0822 - val_accuracy: 0.9782\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1039 - accuracy: 0.9712 - val_loss: 0.0822 - val_accuracy: 0.9782\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1039 - accuracy: 0.9712 - val_loss: 0.0822 - val_accuracy: 0.9782\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1038 - accuracy: 0.9713 - val_loss: 0.0822 - val_accuracy: 0.9782\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1038 - accuracy: 0.9713 - val_loss: 0.0822 - val_accuracy: 0.9782\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1038 - accuracy: 0.9713 - val_loss: 0.0822 - val_accuracy: 0.9782\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1038 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1038 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1038 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1038 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9714 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9714 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9714 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9782\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer= \"sgd\",\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "fitted_model = model.fit(x_train,y_train,validation_data=(x_dev,y_dev),epochs=100,callbacks = [tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "527e0271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6200823783874512,\n",
       "  0.2914898693561554,\n",
       "  0.24247609078884125,\n",
       "  0.21282468736171722,\n",
       "  0.19292840361595154,\n",
       "  0.17746837437152863,\n",
       "  0.16585558652877808,\n",
       "  0.15655487775802612,\n",
       "  0.14871464669704437,\n",
       "  0.14275449514389038,\n",
       "  0.13725493848323822,\n",
       "  0.13299335539340973,\n",
       "  0.12924760580062866,\n",
       "  0.1260017305612564,\n",
       "  0.12328295409679413,\n",
       "  0.12084194272756577,\n",
       "  0.11886189877986908,\n",
       "  0.11704883724451065,\n",
       "  0.11555403470993042,\n",
       "  0.11412755399942398,\n",
       "  0.1128537505865097,\n",
       "  0.11194588243961334,\n",
       "  0.11095449328422546,\n",
       "  0.11016163229942322,\n",
       "  0.10937875509262085,\n",
       "  0.1087854653596878,\n",
       "  0.10818780958652496,\n",
       "  0.10772073268890381,\n",
       "  0.1072748526930809,\n",
       "  0.10686168819665909,\n",
       "  0.10652310401201248,\n",
       "  0.10620391368865967,\n",
       "  0.10590333491563797,\n",
       "  0.10569433122873306,\n",
       "  0.10545797646045685,\n",
       "  0.10526765137910843,\n",
       "  0.10509661585092545,\n",
       "  0.10493771731853485,\n",
       "  0.10479743033647537,\n",
       "  0.10468257963657379,\n",
       "  0.10456953942775726,\n",
       "  0.1044744923710823,\n",
       "  0.10438694059848785,\n",
       "  0.10431090742349625,\n",
       "  0.10424096137285233,\n",
       "  0.10417921096086502,\n",
       "  0.10412582755088806,\n",
       "  0.10407472401857376,\n",
       "  0.10403319448232651,\n",
       "  0.10399413853883743,\n",
       "  0.10395970940589905,\n",
       "  0.10392855852842331,\n",
       "  0.10390079766511917,\n",
       "  0.10387708991765976,\n",
       "  0.10385534167289734,\n",
       "  0.10383591055870056,\n",
       "  0.1038188561797142,\n",
       "  0.10380329936742783,\n",
       "  0.10378990322351456,\n",
       "  0.10377775132656097,\n",
       "  0.10376680642366409,\n",
       "  0.10375703871250153,\n",
       "  0.1037486344575882,\n",
       "  0.10374093055725098,\n",
       "  0.10373406112194061,\n",
       "  0.10372807085514069,\n",
       "  0.1037227213382721,\n",
       "  0.10371790826320648,\n",
       "  0.10371382534503937,\n",
       "  0.10371008515357971,\n",
       "  0.10370678454637527,\n",
       "  0.10370390862226486,\n",
       "  0.103701151907444,\n",
       "  0.10369901359081268,\n",
       "  0.1036970242857933,\n",
       "  0.10369513928890228,\n",
       "  0.10369360446929932,\n",
       "  0.10369230806827545,\n",
       "  0.10369086265563965,\n",
       "  0.10368985682725906,\n",
       "  0.1036887839436531,\n",
       "  0.1036880686879158,\n",
       "  0.10368738323450089,\n",
       "  0.10368657112121582,\n",
       "  0.10368618369102478,\n",
       "  0.10368569195270538,\n",
       "  0.10368531942367554,\n",
       "  0.10368482768535614,\n",
       "  0.10368464887142181,\n",
       "  0.10368428379297256,\n",
       "  0.10368415713310242,\n",
       "  0.10368376225233078,\n",
       "  0.10368362814188004,\n",
       "  0.10368344932794571,\n",
       "  0.10368344932794571,\n",
       "  0.10368333011865616,\n",
       "  0.10368330031633377,\n",
       "  0.10368315130472183,\n",
       "  0.10368313640356064,\n",
       "  0.10368302464485168],\n",
       " 'accuracy': [0.8369333148002625,\n",
       "  0.9161666631698608,\n",
       "  0.9317166805267334,\n",
       "  0.9390333294868469,\n",
       "  0.9452499747276306,\n",
       "  0.9495499730110168,\n",
       "  0.9518833160400391,\n",
       "  0.9553166627883911,\n",
       "  0.9576333165168762,\n",
       "  0.9590166807174683,\n",
       "  0.9612166881561279,\n",
       "  0.9623666405677795,\n",
       "  0.9635000228881836,\n",
       "  0.9643833041191101,\n",
       "  0.965583324432373,\n",
       "  0.9663833379745483,\n",
       "  0.9665666818618774,\n",
       "  0.9673333168029785,\n",
       "  0.9676833152770996,\n",
       "  0.9682166576385498,\n",
       "  0.9684333205223083,\n",
       "  0.9688500165939331,\n",
       "  0.9691166877746582,\n",
       "  0.9691333174705505,\n",
       "  0.9695000052452087,\n",
       "  0.9695666432380676,\n",
       "  0.9700666666030884,\n",
       "  0.9701666831970215,\n",
       "  0.9702333211898804,\n",
       "  0.9702833294868469,\n",
       "  0.970633327960968,\n",
       "  0.9703999757766724,\n",
       "  0.9708333611488342,\n",
       "  0.970883309841156,\n",
       "  0.9708666801452637,\n",
       "  0.9708999991416931,\n",
       "  0.9709500074386597,\n",
       "  0.9710166454315186,\n",
       "  0.9710666537284851,\n",
       "  0.9710666537284851,\n",
       "  0.9710333347320557,\n",
       "  0.9711333513259888,\n",
       "  0.9711333513259888,\n",
       "  0.9711666703224182,\n",
       "  0.9711999893188477,\n",
       "  0.9711666703224182,\n",
       "  0.9712166786193848,\n",
       "  0.9711666703224182,\n",
       "  0.9712333083152771,\n",
       "  0.9712166786193848,\n",
       "  0.9712166786193848,\n",
       "  0.9712333083152771,\n",
       "  0.9713000059127808,\n",
       "  0.9712499976158142,\n",
       "  0.9712499976158142,\n",
       "  0.9712666869163513,\n",
       "  0.9712833166122437,\n",
       "  0.9713166952133179,\n",
       "  0.9713333249092102,\n",
       "  0.9713166952133179,\n",
       "  0.9713000059127808,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713500142097473,\n",
       "  0.9713166952133179,\n",
       "  0.9713333249092102,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713500142097473,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713166952133179,\n",
       "  0.9713500142097473,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713333249092102,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179,\n",
       "  0.9713166952133179],\n",
       " 'val_loss': [0.2574714124202728,\n",
       "  0.2003299593925476,\n",
       "  0.17331261932849884,\n",
       "  0.15397916734218597,\n",
       "  0.1415439397096634,\n",
       "  0.13038869202136993,\n",
       "  0.12340780347585678,\n",
       "  0.11610288172960281,\n",
       "  0.11073403060436249,\n",
       "  0.1074596643447876,\n",
       "  0.10436940938234329,\n",
       "  0.10137501358985901,\n",
       "  0.09845785796642303,\n",
       "  0.09613430500030518,\n",
       "  0.09480669349431992,\n",
       "  0.09350970387458801,\n",
       "  0.09222125262022018,\n",
       "  0.09081417322158813,\n",
       "  0.08997073769569397,\n",
       "  0.08885642141103745,\n",
       "  0.08886666595935822,\n",
       "  0.08739424496889114,\n",
       "  0.08664580434560776,\n",
       "  0.08638674020767212,\n",
       "  0.08563008159399033,\n",
       "  0.08522576093673706,\n",
       "  0.08521365374326706,\n",
       "  0.08470243960618973,\n",
       "  0.08451522886753082,\n",
       "  0.08411626517772675,\n",
       "  0.08392447233200073,\n",
       "  0.08368869870901108,\n",
       "  0.08368636667728424,\n",
       "  0.0833190307021141,\n",
       "  0.083312027156353,\n",
       "  0.08305791765451431,\n",
       "  0.08295038342475891,\n",
       "  0.08289779722690582,\n",
       "  0.08285365253686905,\n",
       "  0.08271275460720062,\n",
       "  0.08262396603822708,\n",
       "  0.08257423341274261,\n",
       "  0.08251917362213135,\n",
       "  0.08246800303459167,\n",
       "  0.0824301689863205,\n",
       "  0.08237175643444061,\n",
       "  0.0823436751961708,\n",
       "  0.08233475685119629,\n",
       "  0.08230574429035187,\n",
       "  0.08228713274002075,\n",
       "  0.08225463330745697,\n",
       "  0.08223317563533783,\n",
       "  0.08220723271369934,\n",
       "  0.08219465613365173,\n",
       "  0.08218199759721756,\n",
       "  0.08216855674982071,\n",
       "  0.0821593850851059,\n",
       "  0.08215166628360748,\n",
       "  0.0821433886885643,\n",
       "  0.08213555812835693,\n",
       "  0.08212865144014359,\n",
       "  0.08212250471115112,\n",
       "  0.08211711794137955,\n",
       "  0.08211228251457214,\n",
       "  0.08210799843072891,\n",
       "  0.0821044072508812,\n",
       "  0.0821012556552887,\n",
       "  0.08209854364395142,\n",
       "  0.08209586888551712,\n",
       "  0.0820934996008873,\n",
       "  0.0820915624499321,\n",
       "  0.08208978921175003,\n",
       "  0.08208819478750229,\n",
       "  0.08208687603473663,\n",
       "  0.0820857509970665,\n",
       "  0.08208468556404114,\n",
       "  0.08208373934030533,\n",
       "  0.08208300918340683,\n",
       "  0.08208226412534714,\n",
       "  0.08208168298006058,\n",
       "  0.0820811316370964,\n",
       "  0.08208062499761581,\n",
       "  0.08208020776510239,\n",
       "  0.08207987248897552,\n",
       "  0.08207953721284866,\n",
       "  0.08207932114601135,\n",
       "  0.08207903802394867,\n",
       "  0.08207884430885315,\n",
       "  0.08207857608795166,\n",
       "  0.08207837492227554,\n",
       "  0.0820782482624054,\n",
       "  0.08207803964614868,\n",
       "  0.08207786828279495,\n",
       "  0.0820777639746666,\n",
       "  0.08207764476537704,\n",
       "  0.08207754045724869,\n",
       "  0.08207755535840988,\n",
       "  0.0820775032043457,\n",
       "  0.08207743614912033,\n",
       "  0.08207736909389496],\n",
       " 'val_accuracy': [0.9319999814033508,\n",
       "  0.946399986743927,\n",
       "  0.9534000158309937,\n",
       "  0.9585999846458435,\n",
       "  0.9638000130653381,\n",
       "  0.965399980545044,\n",
       "  0.9675999879837036,\n",
       "  0.9682000279426575,\n",
       "  0.9703999757766724,\n",
       "  0.9715999960899353,\n",
       "  0.9728000164031982,\n",
       "  0.9735999703407288,\n",
       "  0.973800003528595,\n",
       "  0.9747999906539917,\n",
       "  0.9751999974250793,\n",
       "  0.975600004196167,\n",
       "  0.9753999710083008,\n",
       "  0.9761999845504761,\n",
       "  0.9771999716758728,\n",
       "  0.9768000245094299,\n",
       "  0.9768000245094299,\n",
       "  0.9771999716758728,\n",
       "  0.9771999716758728,\n",
       "  0.9775999784469604,\n",
       "  0.9765999913215637,\n",
       "  0.9771999716758728,\n",
       "  0.9771999716758728,\n",
       "  0.9778000116348267,\n",
       "  0.977400004863739,\n",
       "  0.9782000184059143,\n",
       "  0.9778000116348267,\n",
       "  0.9779999852180481,\n",
       "  0.9778000116348267,\n",
       "  0.9779999852180481,\n",
       "  0.9775999784469604,\n",
       "  0.9779999852180481,\n",
       "  0.9779999852180481,\n",
       "  0.9779999852180481,\n",
       "  0.9779999852180481,\n",
       "  0.9779999852180481,\n",
       "  0.9779999852180481,\n",
       "  0.9779999852180481,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9779999852180481,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143,\n",
       "  0.9782000184059143],\n",
       " 'lr': [0.008912509,\n",
       "  0.007943282,\n",
       "  0.0070794574,\n",
       "  0.006309573,\n",
       "  0.005623413,\n",
       "  0.005011872,\n",
       "  0.0044668354,\n",
       "  0.003981071,\n",
       "  0.0035481334,\n",
       "  0.0031622772,\n",
       "  0.0028183826,\n",
       "  0.0025118862,\n",
       "  0.002238721,\n",
       "  0.001995262,\n",
       "  0.0017782791,\n",
       "  0.0015848929,\n",
       "  0.0014125373,\n",
       "  0.0012589252,\n",
       "  0.0011220182,\n",
       "  0.0009999998,\n",
       "  0.0008912508,\n",
       "  0.0007943281,\n",
       "  0.00070794567,\n",
       "  0.00063095725,\n",
       "  0.00056234124,\n",
       "  0.00050118717,\n",
       "  0.00044668352,\n",
       "  0.0003981071,\n",
       "  0.00035481332,\n",
       "  0.0003162277,\n",
       "  0.00028183823,\n",
       "  0.00025118858,\n",
       "  0.00022387206,\n",
       "  0.00019952618,\n",
       "  0.0001778279,\n",
       "  0.00015848927,\n",
       "  0.00014125371,\n",
       "  0.0001258925,\n",
       "  0.000112201815,\n",
       "  9.9999976e-05,\n",
       "  8.9125075e-05,\n",
       "  7.943281e-05,\n",
       "  7.0794566e-05,\n",
       "  6.309572e-05,\n",
       "  5.6234123e-05,\n",
       "  5.0118713e-05,\n",
       "  4.466835e-05,\n",
       "  3.981071e-05,\n",
       "  3.5481335e-05,\n",
       "  3.1622774e-05,\n",
       "  2.8183827e-05,\n",
       "  2.5118863e-05,\n",
       "  2.238721e-05,\n",
       "  1.9952622e-05,\n",
       "  1.7782793e-05,\n",
       "  1.5848931e-05,\n",
       "  1.4125375e-05,\n",
       "  1.2589254e-05,\n",
       "  1.1220184e-05,\n",
       "  1e-05,\n",
       "  8.912509e-06,\n",
       "  7.943282e-06,\n",
       "  7.0794576e-06,\n",
       "  6.309573e-06,\n",
       "  5.623413e-06,\n",
       "  5.011872e-06,\n",
       "  4.4668354e-06,\n",
       "  3.981071e-06,\n",
       "  3.5481335e-06,\n",
       "  3.1622774e-06,\n",
       "  2.8183827e-06,\n",
       "  2.5118861e-06,\n",
       "  2.2387208e-06,\n",
       "  1.995262e-06,\n",
       "  1.7782792e-06,\n",
       "  1.584893e-06,\n",
       "  1.4125374e-06,\n",
       "  1.2589253e-06,\n",
       "  1.1220184e-06,\n",
       "  9.999999e-07,\n",
       "  8.912508e-07,\n",
       "  7.943281e-07,\n",
       "  7.079457e-07,\n",
       "  6.3095723e-07,\n",
       "  5.623412e-07,\n",
       "  5.011871e-07,\n",
       "  4.466835e-07,\n",
       "  3.981071e-07,\n",
       "  3.5481332e-07,\n",
       "  3.162277e-07,\n",
       "  2.8183823e-07,\n",
       "  2.511886e-07,\n",
       "  2.2387208e-07,\n",
       "  1.995262e-07,\n",
       "  1.7782791e-07,\n",
       "  1.584893e-07,\n",
       "  1.4125374e-07,\n",
       "  1.2589253e-07,\n",
       "  1.1220183e-07,\n",
       "  9.999999e-08]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8ef5716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11ee7b398e0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fitted_model.history['lr'], fitted_model.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6c80a",
   "metadata": {},
   "source": [
    "# Step 7 - What is the value of lr when loss shoots up? Report answer.\n",
    "\n",
    "value of LR where loss shoots up is 0.008"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90a57b",
   "metadata": {},
   "source": [
    "# Step 9 - Use earlystoppping() when the desired metric has stopped improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e4f0acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1060 - accuracy: 0.9697 - val_loss: 0.0765 - val_accuracy: 0.9790\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0976 - accuracy: 0.9722 - val_loss: 0.0721 - val_accuracy: 0.9822: 1s - loss: 0.099\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0906 - accuracy: 0.9745 - val_loss: 0.0673 - val_accuracy: 0.98280s - loss: 0.0917 - accuracy\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0849 - accuracy: 0.9765 - val_loss: 0.0662 - val_accuracy: 0.9838s: 0.0844 - accura\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0806 - accuracy: 0.9771 - val_loss: 0.0604 - val_accuracy: 0.9850\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0767 - accuracy: 0.9787 - val_loss: 0.0600 - val_accuracy: 0.9846\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0734 - accuracy: 0.9800 - val_loss: 0.0561 - val_accuracy: 0.9852\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0708 - accuracy: 0.9806 - val_loss: 0.0532 - val_accuracy: 0.9862\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0683 - accuracy: 0.9818 - val_loss: 0.0532 - val_accuracy: 0.9864\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0663 - accuracy: 0.9823 - val_loss: 0.0522 - val_accuracy: 0.9868\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0647 - accuracy: 0.9827 - val_loss: 0.0515 - val_accuracy: 0.9868\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0631 - accuracy: 0.9833 - val_loss: 0.0488 - val_accuracy: 0.9874\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0619 - accuracy: 0.9836 - val_loss: 0.0486 - val_accuracy: 0.9872\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0608 - accuracy: 0.9839 - val_loss: 0.0483 - val_accuracy: 0.9874\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0597 - accuracy: 0.9843 - val_loss: 0.0480 - val_accuracy: 0.9874\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0590 - accuracy: 0.9847 - val_loss: 0.0468 - val_accuracy: 0.9884\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0582 - accuracy: 0.9848 - val_loss: 0.0472 - val_accuracy: 0.9886\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0576 - accuracy: 0.9851 - val_loss: 0.0466 - val_accuracy: 0.9884\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0570 - accuracy: 0.9850 - val_loss: 0.0460 - val_accuracy: 0.9888\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0564 - accuracy: 0.9855 - val_loss: 0.0458 - val_accuracy: 0.9888\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0559 - accuracy: 0.9854 - val_loss: 0.0448 - val_accuracy: 0.9890\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0556 - accuracy: 0.9856 - val_loss: 0.0450 - val_accuracy: 0.9884\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0552 - accuracy: 0.9857 - val_loss: 0.0448 - val_accuracy: 0.9890\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0549 - accuracy: 0.9858 - val_loss: 0.0443 - val_accuracy: 0.9890\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0546 - accuracy: 0.9861 - val_loss: 0.0441 - val_accuracy: 0.9894\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0544 - accuracy: 0.9861 - val_loss: 0.0439 - val_accuracy: 0.9892\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0542 - accuracy: 0.9860 - val_loss: 0.0441 - val_accuracy: 0.9890\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0540 - accuracy: 0.9861 - val_loss: 0.0437 - val_accuracy: 0.9892\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0538 - accuracy: 0.9862 - val_loss: 0.0439 - val_accuracy: 0.9892\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0536 - accuracy: 0.9863 - val_loss: 0.0436 - val_accuracy: 0.9892\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0535 - accuracy: 0.9863 - val_loss: 0.0435 - val_accuracy: 0.9894\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0534 - accuracy: 0.9864 - val_loss: 0.0434 - val_accuracy: 0.9892\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0533 - accuracy: 0.9863 - val_loss: 0.0433 - val_accuracy: 0.9892\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0532 - accuracy: 0.9864 - val_loss: 0.0433 - val_accuracy: 0.9894\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0531 - accuracy: 0.9865 - val_loss: 0.0432 - val_accuracy: 0.9894\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0530 - accuracy: 0.9864 - val_loss: 0.0433 - val_accuracy: 0.9894\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0529 - accuracy: 0.9865 - val_loss: 0.0431 - val_accuracy: 0.9894\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0529 - accuracy: 0.9864 - val_loss: 0.0431 - val_accuracy: 0.9894\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0528 - accuracy: 0.9865 - val_loss: 0.0431 - val_accuracy: 0.9894\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0528 - accuracy: 0.9865 - val_loss: 0.0431 - val_accuracy: 0.9894\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0527 - accuracy: 0.9865 - val_loss: 0.0431 - val_accuracy: 0.9894\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0527 - accuracy: 0.9865 - val_loss: 0.0430 - val_accuracy: 0.9894\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0527 - accuracy: 0.9865 - val_loss: 0.0430 - val_accuracy: 0.9894\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0526 - accuracy: 0.9865 - val_loss: 0.0430 - val_accuracy: 0.9894\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0526 - accuracy: 0.9866 - val_loss: 0.0430 - val_accuracy: 0.9894\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0526 - accuracy: 0.9866 - val_loss: 0.0429 - val_accuracy: 0.9894\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0525 - accuracy: 0.9865 - val_loss: 0.0429 - val_accuracy: 0.9894\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0525 - accuracy: 0.9866 - val_loss: 0.0429 - val_accuracy: 0.9894\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0525 - accuracy: 0.9866 - val_loss: 0.0429 - val_accuracy: 0.9894\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0525 - accuracy: 0.9866 - val_loss: 0.0429 - val_accuracy: 0.9894\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0525 - accuracy: 0.9866 - val_loss: 0.0429 - val_accuracy: 0.9894\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0525 - accuracy: 0.9866 - val_loss: 0.0429 - val_accuracy: 0.9894\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0525 - accuracy: 0.9866 - val_loss: 0.0429 - val_accuracy: 0.9894\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0429 - val_accuracy: 0.9894\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0429 - val_accuracy: 0.9894\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0429 - val_accuracy: 0.9894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0429 - val_accuracy: 0.9894\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0429 - val_accuracy: 0.9894\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894s: 0.0520 - ac - ETA: 0s - loss: 0.0523 - \n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.98948 - \n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.0428 - val_accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer= \"sgd\",\n",
    "metrics=[\"accuracy\"])\n",
    "#early stopping\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "restore_best_weights=True)\n",
    "\n",
    "\n",
    "fitted_model = model.fit(x_train,y_train,validation_data=(x_dev,y_dev),epochs=100,callbacks = [tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn),early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "460a78e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.10604789108037949,\n",
       "  0.09761937707662582,\n",
       "  0.09057873487472534,\n",
       "  0.08486243337392807,\n",
       "  0.08058758080005646,\n",
       "  0.07667405903339386,\n",
       "  0.07340098917484283,\n",
       "  0.07084229588508606,\n",
       "  0.06830092519521713,\n",
       "  0.06634629517793655,\n",
       "  0.06465878337621689,\n",
       "  0.06310289353132248,\n",
       "  0.06194789335131645,\n",
       "  0.06080545112490654,\n",
       "  0.05974467471241951,\n",
       "  0.058975160121917725,\n",
       "  0.0582110770046711,\n",
       "  0.057564690709114075,\n",
       "  0.0569603256881237,\n",
       "  0.05638556182384491,\n",
       "  0.0559411346912384,\n",
       "  0.05557543411850929,\n",
       "  0.055235181003808975,\n",
       "  0.05486948415637016,\n",
       "  0.05463876202702522,\n",
       "  0.054386205971241,\n",
       "  0.05415552109479904,\n",
       "  0.0539739653468132,\n",
       "  0.05378163233399391,\n",
       "  0.05362321436405182,\n",
       "  0.053517699241638184,\n",
       "  0.05336642637848854,\n",
       "  0.053261686116456985,\n",
       "  0.0531756617128849,\n",
       "  0.053084734827280045,\n",
       "  0.052991461008787155,\n",
       "  0.05293366312980652,\n",
       "  0.0528770312666893,\n",
       "  0.05281912907958031,\n",
       "  0.052771780639886856,\n",
       "  0.052727315574884415,\n",
       "  0.052687808871269226,\n",
       "  0.05265369638800621,\n",
       "  0.05262117460370064,\n",
       "  0.05259516462683678,\n",
       "  0.052569907158613205,\n",
       "  0.052548229694366455,\n",
       "  0.05252838879823685,\n",
       "  0.05251172184944153,\n",
       "  0.05249575152993202,\n",
       "  0.052482180297374725,\n",
       "  0.0524696484208107,\n",
       "  0.05245880037546158,\n",
       "  0.05244894325733185,\n",
       "  0.05244038999080658,\n",
       "  0.05243275687098503,\n",
       "  0.052425798028707504,\n",
       "  0.05241961032152176,\n",
       "  0.052414119243621826,\n",
       "  0.05240916088223457,\n",
       "  0.05240496248006821,\n",
       "  0.05240115523338318,\n",
       "  0.05239775404334068,\n",
       "  0.05239463597536087,\n",
       "  0.052392005920410156,\n",
       "  0.05238965526223183,\n",
       "  0.052387408912181854,\n",
       "  0.0523856095969677,\n",
       "  0.052383940666913986,\n",
       "  0.05238242819905281,\n",
       "  0.052381131798028946,\n",
       "  0.052379969507455826,\n",
       "  0.05237888917326927,\n",
       "  0.05237806960940361,\n",
       "  0.05237722396850586,\n",
       "  0.052376553416252136,\n",
       "  0.052375879138708115,\n",
       "  0.05237548053264618,\n",
       "  0.052374958992004395,\n",
       "  0.052374470978975296,\n",
       "  0.052374016493558884,\n",
       "  0.05237371101975441,\n",
       "  0.052373528480529785,\n",
       "  0.05237328261137009,\n",
       "  0.05237312987446785,\n",
       "  0.052372805774211884,\n",
       "  0.052372708916664124,\n",
       "  0.052372533828020096,\n",
       "  0.052372343838214874,\n",
       "  0.05237229913473129,\n",
       "  0.05237223953008652,\n",
       "  0.052372101694345474,\n",
       "  0.052372049540281296,\n",
       "  0.05237197130918503,\n",
       "  0.05237196385860443,\n",
       "  0.05237186700105667,\n",
       "  0.05237186327576637,\n",
       "  0.05237181857228279,\n",
       "  0.052371796220541,\n",
       "  0.05237177386879921],\n",
       " 'accuracy': [0.9696666598320007,\n",
       "  0.9721999764442444,\n",
       "  0.9745333194732666,\n",
       "  0.9764999747276306,\n",
       "  0.9771166443824768,\n",
       "  0.9787499904632568,\n",
       "  0.9799833297729492,\n",
       "  0.980566680431366,\n",
       "  0.9818000197410583,\n",
       "  0.9823166728019714,\n",
       "  0.9827166795730591,\n",
       "  0.9832666516304016,\n",
       "  0.9836000204086304,\n",
       "  0.9838666915893555,\n",
       "  0.9842833280563354,\n",
       "  0.9847166538238525,\n",
       "  0.9848499894142151,\n",
       "  0.9850500226020813,\n",
       "  0.9850333333015442,\n",
       "  0.985450029373169,\n",
       "  0.9854333400726318,\n",
       "  0.9855833053588867,\n",
       "  0.9856833219528198,\n",
       "  0.9858499765396118,\n",
       "  0.9861166477203369,\n",
       "  0.986050009727478,\n",
       "  0.9859833121299744,\n",
       "  0.9860833287239075,\n",
       "  0.9862333536148071,\n",
       "  0.9863499999046326,\n",
       "  0.986299991607666,\n",
       "  0.986383318901062,\n",
       "  0.9863499999046326,\n",
       "  0.986383318901062,\n",
       "  0.986466646194458,\n",
       "  0.9864166378974915,\n",
       "  0.9865000247955322,\n",
       "  0.9864000082015991,\n",
       "  0.9864833354949951,\n",
       "  0.9865000247955322,\n",
       "  0.9865000247955322,\n",
       "  0.9865333437919617,\n",
       "  0.9865333437919617,\n",
       "  0.986549973487854,\n",
       "  0.9865999817848206,\n",
       "  0.9865833520889282,\n",
       "  0.9865166544914246,\n",
       "  0.9866166710853577,\n",
       "  0.9865999817848206,\n",
       "  0.9865833520889282,\n",
       "  0.9865999817848206,\n",
       "  0.9866166710853577,\n",
       "  0.9866166710853577,\n",
       "  0.9866166710853577,\n",
       "  0.9866333603858948,\n",
       "  0.9866166710853577,\n",
       "  0.9866333603858948,\n",
       "  0.9866166710853577,\n",
       "  0.9866166710853577,\n",
       "  0.9866333603858948,\n",
       "  0.9866166710853577,\n",
       "  0.9866499900817871,\n",
       "  0.9866333603858948,\n",
       "  0.9866499900817871,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866499900817871,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866499900817871,\n",
       "  0.9866499900817871,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866333603858948,\n",
       "  0.9866499900817871,\n",
       "  0.9866499900817871,\n",
       "  0.9866499900817871,\n",
       "  0.9866499900817871,\n",
       "  0.9866499900817871,\n",
       "  0.9866499900817871,\n",
       "  0.9866499900817871,\n",
       "  0.9866499900817871,\n",
       "  0.9866499900817871,\n",
       "  0.9866499900817871,\n",
       "  0.9866499900817871],\n",
       " 'val_loss': [0.07649312913417816,\n",
       "  0.07211318612098694,\n",
       "  0.06727689504623413,\n",
       "  0.066215381026268,\n",
       "  0.06035599857568741,\n",
       "  0.06004771217703819,\n",
       "  0.05611315742135048,\n",
       "  0.05322729051113129,\n",
       "  0.053170911967754364,\n",
       "  0.05221741273999214,\n",
       "  0.05147559940814972,\n",
       "  0.048764534294605255,\n",
       "  0.048550233244895935,\n",
       "  0.048297882080078125,\n",
       "  0.048011474311351776,\n",
       "  0.04678728058934212,\n",
       "  0.04721252620220184,\n",
       "  0.04660957679152489,\n",
       "  0.045963168144226074,\n",
       "  0.045797254890203476,\n",
       "  0.044828154146671295,\n",
       "  0.04502822458744049,\n",
       "  0.044823627918958664,\n",
       "  0.04431794583797455,\n",
       "  0.04407639801502228,\n",
       "  0.04393135756254196,\n",
       "  0.04412408918142319,\n",
       "  0.04368739202618599,\n",
       "  0.04385363310575485,\n",
       "  0.043630100786685944,\n",
       "  0.043512195348739624,\n",
       "  0.04339728504419327,\n",
       "  0.04328335076570511,\n",
       "  0.04334888979792595,\n",
       "  0.043208736926317215,\n",
       "  0.04330870509147644,\n",
       "  0.043136563152074814,\n",
       "  0.04311532899737358,\n",
       "  0.043083980679512024,\n",
       "  0.043051183223724365,\n",
       "  0.04305897280573845,\n",
       "  0.0430157370865345,\n",
       "  0.04297368600964546,\n",
       "  0.04297242686152458,\n",
       "  0.042958345264196396,\n",
       "  0.042930714786052704,\n",
       "  0.042929209768772125,\n",
       "  0.042913757264614105,\n",
       "  0.0429043173789978,\n",
       "  0.042895715683698654,\n",
       "  0.042888954281806946,\n",
       "  0.042879849672317505,\n",
       "  0.04287625476717949,\n",
       "  0.0428728386759758,\n",
       "  0.042866095900535583,\n",
       "  0.04286090284585953,\n",
       "  0.04285595566034317,\n",
       "  0.0428520105779171,\n",
       "  0.04284798353910446,\n",
       "  0.04284507408738136,\n",
       "  0.04284321889281273,\n",
       "  0.04284064471721649,\n",
       "  0.04283883795142174,\n",
       "  0.042836736887693405,\n",
       "  0.042835332453250885,\n",
       "  0.04283382371068001,\n",
       "  0.042832691222429276,\n",
       "  0.04283161461353302,\n",
       "  0.042830608785152435,\n",
       "  0.04282992705702782,\n",
       "  0.04282921925187111,\n",
       "  0.042828790843486786,\n",
       "  0.042828258126974106,\n",
       "  0.042827900499105453,\n",
       "  0.04282752424478531,\n",
       "  0.04282727092504501,\n",
       "  0.04282695800065994,\n",
       "  0.042826805263757706,\n",
       "  0.0428265780210495,\n",
       "  0.04282635077834129,\n",
       "  0.04282619431614876,\n",
       "  0.042826130986213684,\n",
       "  0.042825937271118164,\n",
       "  0.042825847864151,\n",
       "  0.04282578453421593,\n",
       "  0.04282566159963608,\n",
       "  0.04282563552260399,\n",
       "  0.04282553866505623,\n",
       "  0.042825452983379364,\n",
       "  0.042825400829315186,\n",
       "  0.04282534494996071,\n",
       "  0.04282529279589653,\n",
       "  0.04282522201538086,\n",
       "  0.04282519966363907,\n",
       "  0.04282514378428459,\n",
       "  0.042825113981962204,\n",
       "  0.04282505810260773,\n",
       "  0.042825035750865936,\n",
       "  0.04282499849796295,\n",
       "  0.04282498359680176],\n",
       " 'val_accuracy': [0.9789999723434448,\n",
       "  0.982200026512146,\n",
       "  0.9828000068664551,\n",
       "  0.9837999939918518,\n",
       "  0.9850000143051147,\n",
       "  0.9846000075340271,\n",
       "  0.9851999878883362,\n",
       "  0.9861999750137329,\n",
       "  0.9864000082015991,\n",
       "  0.9868000149726868,\n",
       "  0.9868000149726868,\n",
       "  0.9873999953269958,\n",
       "  0.9872000217437744,\n",
       "  0.9873999953269958,\n",
       "  0.9873999953269958,\n",
       "  0.9883999824523926,\n",
       "  0.9886000156402588,\n",
       "  0.9883999824523926,\n",
       "  0.9887999892234802,\n",
       "  0.9887999892234802,\n",
       "  0.9890000224113464,\n",
       "  0.9883999824523926,\n",
       "  0.9890000224113464,\n",
       "  0.9890000224113464,\n",
       "  0.9894000291824341,\n",
       "  0.9891999959945679,\n",
       "  0.9890000224113464,\n",
       "  0.9891999959945679,\n",
       "  0.9891999959945679,\n",
       "  0.9891999959945679,\n",
       "  0.9894000291824341,\n",
       "  0.9891999959945679,\n",
       "  0.9891999959945679,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341,\n",
       "  0.9894000291824341],\n",
       " 'lr': [0.008912509,\n",
       "  0.007943282,\n",
       "  0.0070794574,\n",
       "  0.006309573,\n",
       "  0.005623413,\n",
       "  0.005011872,\n",
       "  0.0044668354,\n",
       "  0.003981071,\n",
       "  0.0035481334,\n",
       "  0.0031622772,\n",
       "  0.0028183826,\n",
       "  0.0025118862,\n",
       "  0.002238721,\n",
       "  0.001995262,\n",
       "  0.0017782791,\n",
       "  0.0015848929,\n",
       "  0.0014125373,\n",
       "  0.0012589252,\n",
       "  0.0011220182,\n",
       "  0.0009999998,\n",
       "  0.0008912508,\n",
       "  0.0007943281,\n",
       "  0.00070794567,\n",
       "  0.00063095725,\n",
       "  0.00056234124,\n",
       "  0.00050118717,\n",
       "  0.00044668352,\n",
       "  0.0003981071,\n",
       "  0.00035481332,\n",
       "  0.0003162277,\n",
       "  0.00028183823,\n",
       "  0.00025118858,\n",
       "  0.00022387206,\n",
       "  0.00019952618,\n",
       "  0.0001778279,\n",
       "  0.00015848927,\n",
       "  0.00014125371,\n",
       "  0.0001258925,\n",
       "  0.000112201815,\n",
       "  9.9999976e-05,\n",
       "  8.9125075e-05,\n",
       "  7.943281e-05,\n",
       "  7.0794566e-05,\n",
       "  6.309572e-05,\n",
       "  5.6234123e-05,\n",
       "  5.0118713e-05,\n",
       "  4.466835e-05,\n",
       "  3.981071e-05,\n",
       "  3.5481335e-05,\n",
       "  3.1622774e-05,\n",
       "  2.8183827e-05,\n",
       "  2.5118863e-05,\n",
       "  2.238721e-05,\n",
       "  1.9952622e-05,\n",
       "  1.7782793e-05,\n",
       "  1.5848931e-05,\n",
       "  1.4125375e-05,\n",
       "  1.2589254e-05,\n",
       "  1.1220184e-05,\n",
       "  1e-05,\n",
       "  8.912509e-06,\n",
       "  7.943282e-06,\n",
       "  7.0794576e-06,\n",
       "  6.309573e-06,\n",
       "  5.623413e-06,\n",
       "  5.011872e-06,\n",
       "  4.4668354e-06,\n",
       "  3.981071e-06,\n",
       "  3.5481335e-06,\n",
       "  3.1622774e-06,\n",
       "  2.8183827e-06,\n",
       "  2.5118861e-06,\n",
       "  2.2387208e-06,\n",
       "  1.995262e-06,\n",
       "  1.7782792e-06,\n",
       "  1.584893e-06,\n",
       "  1.4125374e-06,\n",
       "  1.2589253e-06,\n",
       "  1.1220184e-06,\n",
       "  9.999999e-07,\n",
       "  8.912508e-07,\n",
       "  7.943281e-07,\n",
       "  7.079457e-07,\n",
       "  6.3095723e-07,\n",
       "  5.623412e-07,\n",
       "  5.011871e-07,\n",
       "  4.466835e-07,\n",
       "  3.981071e-07,\n",
       "  3.5481332e-07,\n",
       "  3.162277e-07,\n",
       "  2.8183823e-07,\n",
       "  2.511886e-07,\n",
       "  2.2387208e-07,\n",
       "  1.995262e-07,\n",
       "  1.7782791e-07,\n",
       "  1.584893e-07,\n",
       "  1.4125374e-07,\n",
       "  1.2589253e-07,\n",
       "  1.1220183e-07,\n",
       "  9.999999e-08]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee776a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11ee7ac0af0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fitted_model.history['lr'], fitted_model.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7078a0",
   "metadata": {},
   "source": [
    "# Step 10 - create checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57747232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0559 - accuracy: 0.9849 - val_loss: 0.0426 - val_accuracy: 0.9894\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0527 - accuracy: 0.9863 - val_loss: 0.0389 - val_accuracy: 0.9904\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0495 - accuracy: 0.9871 - val_loss: 0.0414 - val_accuracy: 0.9880\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0471 - accuracy: 0.9875 - val_loss: 0.0361 - val_accuracy: 0.9912\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0449 - accuracy: 0.9883 - val_loss: 0.0352 - val_accuracy: 0.9920\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0430 - accuracy: 0.9894 - val_loss: 0.0333 - val_accuracy: 0.9920\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0414 - accuracy: 0.9898 - val_loss: 0.0334 - val_accuracy: 0.9934\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0400 - accuracy: 0.9901 - val_loss: 0.0315 - val_accuracy: 0.9928\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0388 - accuracy: 0.9905 - val_loss: 0.0314 - val_accuracy: 0.9924\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0379 - accuracy: 0.9911 - val_loss: 0.0310 - val_accuracy: 0.9926\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0371 - accuracy: 0.9915 - val_loss: 0.0311 - val_accuracy: 0.9930\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0362 - accuracy: 0.9915 - val_loss: 0.0298 - val_accuracy: 0.9938\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0356 - accuracy: 0.9916 - val_loss: 0.0289 - val_accuracy: 0.9926\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0350 - accuracy: 0.9917 - val_loss: 0.0289 - val_accuracy: 0.9942\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0346 - accuracy: 0.9919 - val_loss: 0.0280 - val_accuracy: 0.9938\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0340 - accuracy: 0.9922 - val_loss: 0.0280 - val_accuracy: 0.9938\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0337 - accuracy: 0.9925 - val_loss: 0.0273 - val_accuracy: 0.9940\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0334 - accuracy: 0.9923 - val_loss: 0.0276 - val_accuracy: 0.9938\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0330 - accuracy: 0.9924 - val_loss: 0.0274 - val_accuracy: 0.9940\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0327 - accuracy: 0.9927 - val_loss: 0.0274 - val_accuracy: 0.9936\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0325 - accuracy: 0.9926 - val_loss: 0.0273 - val_accuracy: 0.9940\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0323 - accuracy: 0.9928 - val_loss: 0.0275 - val_accuracy: 0.9942\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0321 - accuracy: 0.9929 - val_loss: 0.0272 - val_accuracy: 0.9940\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0319 - accuracy: 0.9929 - val_loss: 0.0267 - val_accuracy: 0.9944\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0318 - accuracy: 0.9929 - val_loss: 0.0268 - val_accuracy: 0.9946\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0317 - accuracy: 0.9931 - val_loss: 0.0266 - val_accuracy: 0.9940\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0315 - accuracy: 0.9931 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0314 - accuracy: 0.9930 - val_loss: 0.0265 - val_accuracy: 0.9942\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0314 - accuracy: 0.9931 - val_loss: 0.0265 - val_accuracy: 0.9942\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0313 - accuracy: 0.9933 - val_loss: 0.0264 - val_accuracy: 0.9942\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0312 - accuracy: 0.9931 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0311 - accuracy: 0.9933 - val_loss: 0.0263 - val_accuracy: 0.9942\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0311 - accuracy: 0.9931 - val_loss: 0.0263 - val_accuracy: 0.9942\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0310 - accuracy: 0.9933 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0310 - accuracy: 0.9933 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0309 - accuracy: 0.9933 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0309 - accuracy: 0.9934 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0309 - accuracy: 0.9933 - val_loss: 0.0263 - val_accuracy: 0.9946\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0308 - accuracy: 0.9933 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0308 - accuracy: 0.9934 - val_loss: 0.0262 - val_accuracy: 0.9944\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0308 - accuracy: 0.9933 - val_loss: 0.0262 - val_accuracy: 0.9944\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0308 - accuracy: 0.9934 - val_loss: 0.0262 - val_accuracy: 0.9944\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0307 - accuracy: 0.9934 - val_loss: 0.0262 - val_accuracy: 0.9944\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0307 - accuracy: 0.9934 - val_loss: 0.0262 - val_accuracy: 0.9944\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0307 - accuracy: 0.9934 - val_loss: 0.0262 - val_accuracy: 0.9944\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0307 - accuracy: 0.9934 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0307 - accuracy: 0.9934 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0307 - accuracy: 0.9934 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0307 - accuracy: 0.9934 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0307 - accuracy: 0.9934 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9934 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0306 - accuracy: 0.9934 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0306 - accuracy: 0.9934 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9934 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9934 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9934 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9944\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer= \"sgd\",\n",
    "metrics=[\"accuracy\"])\n",
    "#early stopping\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "restore_best_weights=True)\n",
    "\n",
    "#checkpoint\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
    "save_best_only=True)\n",
    "\n",
    "fitted_model = model.fit(x_train,y_train,validation_data=(x_dev,y_dev),epochs=100,callbacks = [tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn),early_stopping_cb,checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3beb1502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.05594524368643761,\n",
       "  0.05265171453356743,\n",
       "  0.04954485967755318,\n",
       "  0.047104109078645706,\n",
       "  0.04485919326543808,\n",
       "  0.04297889396548271,\n",
       "  0.04140784591436386,\n",
       "  0.03998570889234543,\n",
       "  0.038817450404167175,\n",
       "  0.03791627660393715,\n",
       "  0.03705544024705887,\n",
       "  0.036201078444719315,\n",
       "  0.03560654819011688,\n",
       "  0.03504673019051552,\n",
       "  0.03458896651864052,\n",
       "  0.03403020277619362,\n",
       "  0.03367963433265686,\n",
       "  0.033356789499521255,\n",
       "  0.03303268551826477,\n",
       "  0.032747261226177216,\n",
       "  0.0325094573199749,\n",
       "  0.03231050819158554,\n",
       "  0.03210826590657234,\n",
       "  0.03192486613988876,\n",
       "  0.031770169734954834,\n",
       "  0.031664494425058365,\n",
       "  0.03154456615447998,\n",
       "  0.03143865987658501,\n",
       "  0.03135579824447632,\n",
       "  0.031264860183000565,\n",
       "  0.03119007684290409,\n",
       "  0.03112764284014702,\n",
       "  0.031072357669472694,\n",
       "  0.031017789617180824,\n",
       "  0.03097057342529297,\n",
       "  0.03093465231359005,\n",
       "  0.030892616137862206,\n",
       "  0.030860314145684242,\n",
       "  0.030828362330794334,\n",
       "  0.030806658789515495,\n",
       "  0.03078126534819603,\n",
       "  0.03075849637389183,\n",
       "  0.03074050322175026,\n",
       "  0.030724748969078064,\n",
       "  0.030709534883499146,\n",
       "  0.030696988105773926,\n",
       "  0.0306843351572752,\n",
       "  0.03067433089017868,\n",
       "  0.03066466934978962,\n",
       "  0.030656389892101288,\n",
       "  0.030648797750473022,\n",
       "  0.030642187222838402,\n",
       "  0.03063626028597355,\n",
       "  0.030631039291620255,\n",
       "  0.030626440420746803,\n",
       "  0.03062216378748417,\n",
       "  0.030618613585829735,\n",
       "  0.030615169554948807,\n",
       "  0.030612187460064888,\n",
       "  0.030609533190727234,\n",
       "  0.03060721792280674,\n",
       "  0.030605098232626915,\n",
       "  0.03060334548354149,\n",
       "  0.03060167469084263,\n",
       "  0.030600177124142647,\n",
       "  0.030598966404795647,\n",
       "  0.030597828328609467,\n",
       "  0.030596744269132614,\n",
       "  0.03059588372707367,\n",
       "  0.03059505484998226,\n",
       "  0.0305943600833416,\n",
       "  0.03059377707540989,\n",
       "  0.030593227595090866,\n",
       "  0.03059276193380356,\n",
       "  0.030592305585741997,\n",
       "  0.030591916292905807,\n",
       "  0.030591649934649467,\n",
       "  0.030591342598199844,\n",
       "  0.030591068789362907,\n",
       "  0.030590873211622238,\n",
       "  0.03059067763388157,\n",
       "  0.030590513721108437,\n",
       "  0.03059033490717411,\n",
       "  0.03059019334614277,\n",
       "  0.030590098351240158,\n",
       "  0.030590008944272995,\n",
       "  0.030589940026402473],\n",
       " 'accuracy': [0.9849333167076111,\n",
       "  0.9863166809082031,\n",
       "  0.9871000051498413,\n",
       "  0.9874500036239624,\n",
       "  0.9882500171661377,\n",
       "  0.9893666505813599,\n",
       "  0.9898333549499512,\n",
       "  0.9901166558265686,\n",
       "  0.9904999732971191,\n",
       "  0.9910833239555359,\n",
       "  0.9914833307266235,\n",
       "  0.9915000200271606,\n",
       "  0.9915833473205566,\n",
       "  0.9916999936103821,\n",
       "  0.9919333457946777,\n",
       "  0.9922166466712952,\n",
       "  0.9924666881561279,\n",
       "  0.9923499822616577,\n",
       "  0.9923833608627319,\n",
       "  0.9926833510398865,\n",
       "  0.9925666451454163,\n",
       "  0.9928333163261414,\n",
       "  0.9928500056266785,\n",
       "  0.992900013923645,\n",
       "  0.992900013923645,\n",
       "  0.9930833578109741,\n",
       "  0.993066668510437,\n",
       "  0.9929666519165039,\n",
       "  0.9931333065032959,\n",
       "  0.9933000206947327,\n",
       "  0.9931333065032959,\n",
       "  0.993316650390625,\n",
       "  0.9931166768074036,\n",
       "  0.9932500123977661,\n",
       "  0.9932666420936584,\n",
       "  0.9932666420936584,\n",
       "  0.9933666586875916,\n",
       "  0.9933333396911621,\n",
       "  0.9933000206947327,\n",
       "  0.9933500289916992,\n",
       "  0.9933000206947327,\n",
       "  0.993399977684021,\n",
       "  0.9933500289916992,\n",
       "  0.9934166669845581,\n",
       "  0.9934166669845581,\n",
       "  0.9933833479881287,\n",
       "  0.9934499859809875,\n",
       "  0.9934333562850952,\n",
       "  0.9934333562850952,\n",
       "  0.9934333562850952,\n",
       "  0.9934333562850952,\n",
       "  0.9934666752815247,\n",
       "  0.9934333562850952,\n",
       "  0.9934499859809875,\n",
       "  0.9934666752815247,\n",
       "  0.9934999942779541,\n",
       "  0.9934499859809875,\n",
       "  0.9934333562850952,\n",
       "  0.9934499859809875,\n",
       "  0.993483304977417,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.993483304977417,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247,\n",
       "  0.9934666752815247],\n",
       " 'val_loss': [0.042555440217256546,\n",
       "  0.038937292993068695,\n",
       "  0.04136501997709274,\n",
       "  0.03613486513495445,\n",
       "  0.03516010567545891,\n",
       "  0.03326186537742615,\n",
       "  0.03338252753019333,\n",
       "  0.0315178707242012,\n",
       "  0.031437866389751434,\n",
       "  0.030997026711702347,\n",
       "  0.031135519966483116,\n",
       "  0.029831308871507645,\n",
       "  0.02889769896864891,\n",
       "  0.02887881174683571,\n",
       "  0.028040381148457527,\n",
       "  0.02798675000667572,\n",
       "  0.027335086837410927,\n",
       "  0.027566436678171158,\n",
       "  0.02744097262620926,\n",
       "  0.027396036311984062,\n",
       "  0.027348501607775688,\n",
       "  0.027451150119304657,\n",
       "  0.02715262770652771,\n",
       "  0.02674323134124279,\n",
       "  0.026831859722733498,\n",
       "  0.026639670133590698,\n",
       "  0.026517800986766815,\n",
       "  0.02647973597049713,\n",
       "  0.026493728160858154,\n",
       "  0.026388781145215034,\n",
       "  0.026541568338871002,\n",
       "  0.026325857266783714,\n",
       "  0.026331378147006035,\n",
       "  0.0262954980134964,\n",
       "  0.026288263499736786,\n",
       "  0.02630528248846531,\n",
       "  0.026267733424901962,\n",
       "  0.026283465325832367,\n",
       "  0.02626279555261135,\n",
       "  0.026210885494947433,\n",
       "  0.026200268417596817,\n",
       "  0.02617422118782997,\n",
       "  0.026181353256106377,\n",
       "  0.02617427334189415,\n",
       "  0.026157889515161514,\n",
       "  0.026139186695218086,\n",
       "  0.026141751557588577,\n",
       "  0.026130959391593933,\n",
       "  0.026124536991119385,\n",
       "  0.02611837163567543,\n",
       "  0.026112552732229233,\n",
       "  0.026109429076313972,\n",
       "  0.026110602542757988,\n",
       "  0.026107564568519592,\n",
       "  0.026105474680662155,\n",
       "  0.026102593168616295,\n",
       "  0.02610006183385849,\n",
       "  0.02609860524535179,\n",
       "  0.026096779853105545,\n",
       "  0.026095427572727203,\n",
       "  0.02609427459537983,\n",
       "  0.0260933805257082,\n",
       "  0.026092324405908585,\n",
       "  0.02609165944159031,\n",
       "  0.026090966537594795,\n",
       "  0.026090381667017937,\n",
       "  0.02608993463218212,\n",
       "  0.02608952671289444,\n",
       "  0.026089239865541458,\n",
       "  0.026088997721672058,\n",
       "  0.026088790968060493,\n",
       "  0.026088684797286987,\n",
       "  0.026088595390319824,\n",
       "  0.026088500395417213,\n",
       "  0.02608838491141796,\n",
       "  0.02608833648264408,\n",
       "  0.026088284328579903,\n",
       "  0.026088304817676544,\n",
       "  0.02608834207057953,\n",
       "  0.026088332757353783,\n",
       "  0.026088355109095573,\n",
       "  0.026088351383805275,\n",
       "  0.0260884128510952,\n",
       "  0.02608843706548214,\n",
       "  0.02608843334019184,\n",
       "  0.026088504120707512,\n",
       "  0.026088541373610497],\n",
       " 'val_accuracy': [0.9894000291824341,\n",
       "  0.9904000163078308,\n",
       "  0.9879999756813049,\n",
       "  0.9911999702453613,\n",
       "  0.9919999837875366,\n",
       "  0.9919999837875366,\n",
       "  0.993399977684021,\n",
       "  0.9927999973297119,\n",
       "  0.9923999905586243,\n",
       "  0.9926000237464905,\n",
       "  0.9929999709129333,\n",
       "  0.9937999844551086,\n",
       "  0.9926000237464905,\n",
       "  0.9941999912261963,\n",
       "  0.9937999844551086,\n",
       "  0.9937999844551086,\n",
       "  0.9940000176429749,\n",
       "  0.9937999844551086,\n",
       "  0.9940000176429749,\n",
       "  0.9936000108718872,\n",
       "  0.9940000176429749,\n",
       "  0.9941999912261963,\n",
       "  0.9940000176429749,\n",
       "  0.9944000244140625,\n",
       "  0.9945999979972839,\n",
       "  0.9940000176429749,\n",
       "  0.9944000244140625,\n",
       "  0.9941999912261963,\n",
       "  0.9941999912261963,\n",
       "  0.9941999912261963,\n",
       "  0.9944000244140625,\n",
       "  0.9941999912261963,\n",
       "  0.9941999912261963,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9945999979972839,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625,\n",
       "  0.9944000244140625],\n",
       " 'lr': [0.008912509,\n",
       "  0.007943282,\n",
       "  0.0070794574,\n",
       "  0.006309573,\n",
       "  0.005623413,\n",
       "  0.005011872,\n",
       "  0.0044668354,\n",
       "  0.003981071,\n",
       "  0.0035481334,\n",
       "  0.0031622772,\n",
       "  0.0028183826,\n",
       "  0.0025118862,\n",
       "  0.002238721,\n",
       "  0.001995262,\n",
       "  0.0017782791,\n",
       "  0.0015848929,\n",
       "  0.0014125373,\n",
       "  0.0012589252,\n",
       "  0.0011220182,\n",
       "  0.0009999998,\n",
       "  0.0008912508,\n",
       "  0.0007943281,\n",
       "  0.00070794567,\n",
       "  0.00063095725,\n",
       "  0.00056234124,\n",
       "  0.00050118717,\n",
       "  0.00044668352,\n",
       "  0.0003981071,\n",
       "  0.00035481332,\n",
       "  0.0003162277,\n",
       "  0.00028183823,\n",
       "  0.00025118858,\n",
       "  0.00022387206,\n",
       "  0.00019952618,\n",
       "  0.0001778279,\n",
       "  0.00015848927,\n",
       "  0.00014125371,\n",
       "  0.0001258925,\n",
       "  0.000112201815,\n",
       "  9.9999976e-05,\n",
       "  8.9125075e-05,\n",
       "  7.943281e-05,\n",
       "  7.0794566e-05,\n",
       "  6.309572e-05,\n",
       "  5.6234123e-05,\n",
       "  5.0118713e-05,\n",
       "  4.466835e-05,\n",
       "  3.981071e-05,\n",
       "  3.5481335e-05,\n",
       "  3.1622774e-05,\n",
       "  2.8183827e-05,\n",
       "  2.5118863e-05,\n",
       "  2.238721e-05,\n",
       "  1.9952622e-05,\n",
       "  1.7782793e-05,\n",
       "  1.5848931e-05,\n",
       "  1.4125375e-05,\n",
       "  1.2589254e-05,\n",
       "  1.1220184e-05,\n",
       "  1e-05,\n",
       "  8.912509e-06,\n",
       "  7.943282e-06,\n",
       "  7.0794576e-06,\n",
       "  6.309573e-06,\n",
       "  5.623413e-06,\n",
       "  5.011872e-06,\n",
       "  4.4668354e-06,\n",
       "  3.981071e-06,\n",
       "  3.5481335e-06,\n",
       "  3.1622774e-06,\n",
       "  2.8183827e-06,\n",
       "  2.5118861e-06,\n",
       "  2.2387208e-06,\n",
       "  1.995262e-06,\n",
       "  1.7782792e-06,\n",
       "  1.584893e-06,\n",
       "  1.4125374e-06,\n",
       "  1.2589253e-06,\n",
       "  1.1220184e-06,\n",
       "  9.999999e-07,\n",
       "  8.912508e-07,\n",
       "  7.943281e-07,\n",
       "  7.079457e-07,\n",
       "  6.3095723e-07,\n",
       "  5.623412e-07,\n",
       "  5.011871e-07,\n",
       "  4.466835e-07]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fitted_model.history['lr'], fitted_model.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37771beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
